{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9670389,"sourceType":"datasetVersion","datasetId":5909461}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dataset Cleaning and Dashboard Creation","metadata":{}},{"cell_type":"markdown","source":"# **Introduction** \nIn this project, we will clean the dataset, identify null values, and prepare the data for visualization using Tableau. Our dataset contains several columns including order details, shipping mode, customer information, and sales data.\n\n**The key steps involved are:**\n1. Loading the dataset\n2. Data inspection\n3. Handling missing values\n4. Preparing the data for analysis\n5. Exporting the cleaned data","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries\n\nIn this section, we will import the necessary libraries for our data analysis and visualization tasks. The libraries we will use are:\n\n- **pandas**: For data manipulation and analysis, especially for handling data in DataFrames.\n- **numpy**: For numerical operations and support for large, multi-dimensional arrays and matrices.\n- **matplotlib.pyplot**: For creating static, animated, and interactive visualizations in Python.\n- **seaborn**: For statistical data visualization built on top of matplotlib, which provides a high-level interface for drawing attractive graphics.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Loading the Data\n\nWe will load the dataset using `pandas` and inspect the first few rows to get an overview of the data.","metadata":{}},{"cell_type":"code","source":"# Load the datasets\ndf1 = pd.read_csv('/kaggle/input/bussiness1/Customer-Raw Data - Business Data Set (Copy-csv)2 - Copy.csv', encoding='ISO-8859-1')\ndf2 = pd.read_csv('/kaggle/input/bussiness1/Del Col- Raw Data - Business Data Set.csv', encoding='ISO-8859-1')\ndf3 = pd.read_csv('/kaggle/input/bussiness1/Product- Raw Data - Business Data Set (Copy-csv) - Copy.csv', encoding='ISO-8859-1')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the first 10 rows\nprint(df2.head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the last 5 rows of the DataFrame df2\nprint(df2.tail())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display summary information about the DataFrame df2\nprint(df2.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print the shape (number of rows and columns) of the DataFrame df2\nprint(df2.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print the shape of the DataFrame df1\nprint(df1.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate descriptive statistics for the DataFrame df2\ndf2.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Data Overview\n**Here is an overview of the dataset. It contains the following columns:**\n\n`Order ID` : Unique identifier for each order\n\n`Order Date` : The date when the order was placed\n\n`Ship Mode`: Shipping method for the order\n\n`Customer ID`: Unique identifier for the customer\n\n`Product ID`: Unique identifier for the product\n\n`Country, City, State, Postal Code`: Location-related information\n\n`Region`: The geographical region of the order\n\n`Category, Sub-Category`: Product categories and subcategories\n\n`Sales`: Total sales amount\n\n`Quantity`: Number of units sold\n\n`Discount`: Discount applied\n\n`Profit`: Profit from the sale\n","metadata":{}},{"cell_type":"markdown","source":"# 3. Checking for Missing Data","metadata":{}},{"cell_type":"markdown","source":" **We’ll now check for missing values to identify any columns that may need cleaning.**","metadata":{}},{"cell_type":"code","source":"df1.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df3.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df2.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**As we can see, some columns like Sales, Quantity, and Profit have missing values.**","metadata":{}},{"cell_type":"markdown","source":"# 4. Handling Missing Values","metadata":{}},{"cell_type":"markdown","source":"**To understand the extent of missing data, we calculate the percentage of nulls in each column.**","metadata":{}},{"cell_type":"code","source":"# Calculating percentage of missing values\nnull_percentage = (df2.isnull().sum() / len(df2)) * 100\nprint(null_percentage)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**If the percentage of missing values is too high, we may consider dropping these columns. Otherwise, we will clean the dataset by either filling or dropping rows with missing values.**","metadata":{}},{"cell_type":"code","source":"df_cleaned = df2.loc[:, null_percentage < 60]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dropping rows with missing values\ndf2_cleaned = df2.dropna()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking if missing values are removed\nprint(df2_cleaned)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Checking for Duplicates in the DataFrame\n","metadata":{}},{"cell_type":"code","source":"# Count the number of duplicate entries in the DataFrame df2\ndf2.duplicated().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove duplicate entries from the DataFrame df2_cleaned\ndf2_cleaned = df2_cleaned.drop_duplicates()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Data Formatting and Preprocessing\n**After handling the missing data, we move on to ensure the correct data types and format for analysis.**\n\n**We convert date columns to datetime format and ensure numerical columns are correctly set.**\n\n","metadata":{}},{"cell_type":"code","source":"# Convert 'Order Date' to datetime format\ndf2_cleaned['Order Date'] = pd.to_datetime(df2_cleaned['Order Date'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the first few rows of the cleaned DataFrame\nprint(df2_cleaned.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df2_cleaned.head())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove leading and trailing whitespace from column names\ndf2_cleaned.columns = df2_cleaned.columns.str.strip()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Check for Zeros in Specific Columns","metadata":{}},{"cell_type":"code","source":"# Check for zeros in the 'Sales' and 'Ship Mode' columns\nzeros_in_col_sales = (df_cleaned['Sales'] == 0).any()\nzeros_in_col_ship_mode = (df_cleaned['Ship Mode'] == 0).any()\n\nif not zeros_in_col_sales and not zeros_in_col_ship_mode:\n    print(\"لا يوجد أصفار في العمودين Sales و Ship Mode.\")\nelse:\n    if zeros_in_col_sales:\n        print(\"يوجد أصفار في العمود Sales.\")\n    if zeros_in_col_ship_mode:\n        print(\"يوجد أصفار في العمود Ship Mode.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Check for Null Values in the DataFrame","metadata":{}},{"cell_type":"code","source":"# Count of null values in each column\nnull_counts = df2_cleaned.isnull().sum()\nprint(null_counts[null_counts > 0])  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace empty strings with None and drop rows with null profit values\ndf2['profit'] = df2['profit'].replace('', None) \ndf2 = df2.dropna(subset=['profit'])  \nprint(df2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 9. Identify Outliers in the 'Sales' Column","metadata":{}},{"cell_type":"code","source":"# Calculate the first and third quartiles\nQ1 = df2['Sales'].quantile(0.25)\nQ3 = df2['Sales'].quantile(0.75)  \nIQR = Q3 - Q1\n\n# Define the bounds for outliers\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Identify outliers\noutliers = df2[(df2['Sales'] < lower_bound) | (df2['Sales'] > upper_bound)]\nprint(outliers)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for Missing Values Again (Count of missing values in each column)\nmissing_values = df2.isnull().sum()\nprint(missing_values)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data Cleaning and Pivot Table Creation\ndf_cleaned = df2[~df2.index.isin(outliers.index)]  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load data from CSV file into a DataFrame\ndf2 = pd.read_csv('/kaggle/input/bussiness1/Del Col- Raw Data - Business Data Set.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 10. Create a Pivot Table for Sales Data","metadata":{}},{"cell_type":"code","source":"# Create a pivot table to summarize sales data by region and category\npivot_table = df2.pivot_table(\n    values='Sales',       \n    index='Region',      \n    columns='Category',  \n    aggfunc='sum',        \n    fill_value=0      \n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 11. Display the Pivot Table","metadata":{}},{"cell_type":"code","source":"print(pivot_table)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}